# ARTalk 项目总览

## 项目简介

ARTalk 是一个**基于自回归模型的语音驱动 3D 头部动画生成系统**。它能够从输入的音频生成逼真的 3D 人脸动画，包括：
- 精准的唇形同步
- 自然的面部表情
- 眼睛眨动
- 头部姿态运动

## 核心概念

### 名词 (Nouns)

| 名词 | 说明 | 维度/规模 |
|------|------|----------|
| **ARTalk** | 主系统，语音驱动 3D 头部动画生成 | - |
| **FLAME** | 3D 人脸模型参数化表示 | 顶点数: 5023 |
| **GAGAvatar** | 真实感头像渲染引擎（基于3D高斯溅射） | - |
| **BitwiseARModel** | 自回归模型，核心生成模型 | - |
| **BITWISE_VAE** | 变分自编码器，用于动作压缩与量化 | - |
| **Motion Code** | 运动参数编码 | 106维 (100表情 + 6姿态) |
| **Style Motion** | 风格运动参考序列 | 50帧 × 106维 |
| **Shape Code** | 形状参数（身份特征） | 300维 |
| **Expression Code** | 表情参数 | 100维 |
| **Pose Code** | 姿态参数 | 6维 (3全局旋转 + 3下颌旋转) |
| **Audio Feature** | 音频特征 | 1024维 (wav2vec) 或 512维 (mimi) |
| **VQ Code** | 向量量化码本索引 | 二值化编码 |

### 动词 (Verbs/Operations)

| 操作 | 说明 | 位置 |
|------|------|------|
| **inference** | 从音频推理动作序列 | `BitwiseARModel.inference()` |
| **encode** | 编码音频/运动特征 | `audio_encoder`, `StyleEncoder` |
| **decode** | 解码动作参数 | `TransformerDecoder` |
| **quantize** | 量化运动码（BSQ量化） | `MultiScaleBSQ.forward()` |
| **render** | 渲染3D网格或高斯splat | `RenderMesh`, `GAGAvatar` |
| **smooth_motion** | 平滑运动序列（Savitzky-Golay滤波） | `ARTAvatarInferEngine.smooth_motion_savgol()` |

### 引擎 (Engines)

```
┌─────────────────────────────────────────────────────────────┐
│                    ARTAvatarInferEngine                      │
│  (主推理引擎 - 整合所有模块)                                   │
└─────────────────────────────────────────────────────────────┘
         │
         ├──► BitwiseARModel (自回归生成引擎)
         │         ├──► audio_encoder (音频编码)
         │         ├──► style_encoder (风格编码)
         │         ├──► attn_blocks (Transformer注意力)
         │         └──► basic_vae (VAE编码解码)
         │
         ├──► FLAMEModel (FLAME人脸模型引擎)
         │         └──► lbs (Linear Blend Skinning)
         │
         ├──► RenderMesh (网格渲染引擎)
         │
         └──► GAGAvatar (高斯splat渲染引擎)
                   ├──► DINOBase (特征提取)
                   ├──► LinearGSGenerator (全局高斯生成)
                   ├──► ConvGSGenerator (局部高斯生成)
                   └──► StyleUNet (超分辨率上采样)
```

### 点火钥匙 (Ignition Keys/Entry Points)

| 入口点 | 说明 | 文件位置 |
|--------|------|----------|
| `inference.py` | 主程序入口 | `inference.py:213` |
| `ARTAvatarInferEngine.__init__()` | 系统初始化 | `inference.py:19` |
| `ARTAvatarInferEngine.inference()` | 核心推理函数 | `inference.py:47` |
| `run_gradio_app()` | Gradio Web界面启动 | `inference.py:98` |

## 主要模块与调用关系

### 数据流图

```
音频输入 (audio.wav)
    │
    ▼
┌─────────────────────┐
│  Audio Encoder      │  (wav2vec2 或 mimi)
│  音频特征提取        │
└─────────────────────┘
    │ [B, L, 1024]
    ▼
┌─────────────────────┐      ┌─────────────────────┐
│ Style Encoder       │◄─────│ Style Motion        │
│ 风格特征提取        │      │ 风格参考动作         │
└─────────────────────┘      └─────────────────────┘
    │ [B, 1, 768]                 [B, 50, 106]
    ▼
┌─────────────────────────────────────────────────┐
│         BitwiseARModel (自回归生成)              │
│  ┌──────────────────────────────────────────┐  │
│  │  Multi-Scale Autoregressive Transformer  │  │
│  │  (多尺度自回归Transformer)                │  │
│  └──────────────────────────────────────────┘  │
└─────────────────────────────────────────────────┘
    │ Motion Codes [B, T, 106]
    ▼
┌─────────────────────┐
│ Savitzky-Golay      │
│ 运动平滑滤波         │
└─────────────────────┘
    │ Smoothed Motion [B, T, 106]
    ▼
┌─────────────────────┐      ┌─────────────────────┐
│   FLAME Model       │◄─────│  Shape Code         │
│   3D人脸网格生成     │      │  (身份参数)          │
└─────────────────────┘      └─────────────────────┘
    │ Vertices [B, T, 5023, 3]
    ▼
┌─────────────────────────────────────────────────┐
│            渲染引擎 (二选一)                      │
│  ┌──────────────┐         ┌──────────────┐     │
│  │ RenderMesh   │   OR    │  GAGAvatar   │     │
│  │ (简单网格)   │         │ (高斯splat)  │     │
│  └──────────────┘         └──────────────┘     │
└─────────────────────────────────────────────────┘
    │ RGB Images [B, T, 512, 512, 3]
    ▼
┌─────────────────────┐
│  write_video()      │
│  保存为MP4视频       │
└─────────────────────┘
    │
    ▼
输出视频 (output.mp4)
```

### 模块层次结构

```
ARTalk/
├── inference.py ..................... 主入口
├── app/
│   ├── models.py .................... BitwiseARModel (核心自回归模型)
│   ├── transformer.py ............... AdaLNSelfAttn (注意力机制)
│   ├── modules/
│   │   ├── bitwise_vae.py ........... BITWISE_VAE (编码解码器)
│   │   ├── style_encoder.py ......... StyleEncoder (风格编码)
│   │   ├── wav2vec.py ............... Wav2Vec2Model (音频编码)
│   │   └── mimi.py .................. MimiModel (音频编码)
│   ├── flame_model/
│   │   ├── FLAME.py ................. FLAMEModel (人脸模型)
│   │   ├── lbs.py ................... Linear Blend Skinning
│   │   └── renderer_utils.py ........ RenderMesh (网格渲染)
│   ├── GAGAvatar/
│   │   ├── models.py ................ GAGAvatar (高斯渲染)
│   │   ├── modules/
│   │   │   ├── dino_base.py ......... DINOBase (特征提取)
│   │   │   └── style_unet.py ........ StyleUNet (超分辨率)
│   │   └── utils_renderer.py ........ render_gaussian (渲染)
│   └── utils_videos.py .............. 视频IO工具
└── assets/
    ├── ARTalk_wav2vec.pt ............ 预训练模型权重
    ├── config.json .................. 模型配置
    ├── FLAME_with_eye.pt ............ FLAME模型数据
    ├── GAGAvatar/ ................... GAGAvatar资源
    └── style_motion/ ................ 风格动作样本
```

## 重要的前10个文件/函数

| 排名 | 文件路径 | 核心功能 | 代码行数 |
|------|----------|----------|----------|
| 1 | `inference.py` | 主入口和推理引擎 | 237 |
| 2 | `app/models.py` | BitwiseARModel自回归模型 | 165 |
| 3 | `app/modules/bitwise_vae.py` | VAE编码器/解码器 | 348 |
| 4 | `app/transformer.py` | Transformer注意力模块 | 119 |
| 5 | `app/flame_model/FLAME.py` | FLAME人脸模型 | 204 |
| 6 | `app/GAGAvatar/models.py` | GAGAvatar渲染器 | 331 |
| 7 | `app/modules/style_encoder.py` | 风格编码器 | 60 |
| 8 | `app/flame_model/lbs.py` | Linear Blend Skinning | 383 |
| 9 | `app/utils_videos.py` | 视频生成工具 | 147 |
| 10 | `app/flame_model/renderer_utils.py` | 渲染工具 | 238 |

## 核心算法流程

### 1. 初始化阶段 (`ARTAvatarInferEngine.__init__`)

```python
1. 加载 ARTalk 预训练权重 (ARTalk_wav2vec.pt)
2. 初始化 BitwiseARModel
   - 加载 BITWISE_VAE (motion编码解码)
   - 加载 audio_encoder (wav2vec2/mimi)
   - 加载 style_encoder
   - 初始化 Transformer attention blocks
3. 初始化 FLAMEModel (3D人脸模型)
4. 初始化 RenderMesh (简单网格渲染器)
5. (可选) 初始化 GAGAvatar (高斯splat渲染器)
```

### 2. 推理阶段 (`ARTAvatarInferEngine.inference`)

```python
输入: audio [B, audio_length], style_motion [B, 50, 106]

步骤:
1. 风格编码
   style_cond = style_encoder(style_motion)  # [B, 1, 768]

2. 音频分块处理 (每块对应 patch_nums[-1]=100 帧)
   for each audio_chunk:
       a. 音频编码
          audio_feat = audio_encoder(audio_chunk)  # [B, L, 1024]

       b. 多尺度插值
          audio_feats = [interpolate(audio_feat, pn)
                         for pn in patch_nums]  # 5个尺度

       c. 自回归生成 (逐尺度)
          for pidx in range(5):  # patch_nums = (1,5,25,50,100)
              - Transformer attention
              - 预测 motion bits
              - 累积生成

       d. 解码运动参数
          motion = vae.vqidx_to_motion(pred_bits)  # [B, 100, 106]

       e. 更新历史
          prev_motion = current_motion

3. 后处理
   - Savitzky-Golay滤波平滑
   - 裁剪到目标长度

输出: pred_motions [B, T, 106]
```

### 3. 渲染阶段 (`ARTAvatarInferEngine.rendering`)

```python
输入: audio, pred_motions [T, 106], shape_id

选项A - 简单网格渲染:
   for each motion in pred_motions:
       1. FLAME生成顶点
          verts = flame_model(shape_code, motion)  # [5023, 3]
       2. 网格渲染
          rgb = mesh_renderer(verts)  # [512, 512, 3]

选项B - GAGAvatar高斯渲染:
   1. 初始化 (仅首次)
      - DINOBase提取特征
      - 生成高斯参数 (全局+局部)
   2. 每帧渲染
      - FLAME生成顶点
      - 更新高斯位置
      - 高斯渲染
      - 超分辨率上采样

输出: 保存为MP4视频
```

## 关键技术点

1. **多尺度自回归生成**:
   - 从粗到细生成运动序列 (1→5→25→50→100帧)
   - 每个尺度使用causal attention mask

2. **二值标量量化 (BSQ)**:
   - 将连续特征量化为二值码
   - 多尺度残差量化
   - 降低模型复杂度

3. **条件生成**:
   - 音频条件: 通过AdaLN调制
   - 风格条件: classifier-free guidance (CFG)

4. **运动平滑**:
   - Savitzky-Golay滤波器
   - 表情: window=5, order=2
   - 姿态: window=9, order=3

5. **FLAME参数化**:
   - Shape: 300维PCA系数
   - Expression: 100维blend shapes
   - Pose: 6维 (3全局 + 3下颌)

6. **高斯溅射渲染**:
   - 全局高斯: 5023个 (对应FLAME顶点)
   - 局部高斯: 2×296² (双侧平面)
   - 可微分渲染

## 配置参数

```json
{
  "VAE_CONFIG": {
    "V_CODE_DIM": 32,              # VQ码本维度
    "V_PATCH_NUMS": [1,5,25,50,100], # 多尺度patch数
    "T_HIDDEN_DIM": 512,           # Transformer隐藏层
    "T_DEPTH": 6,                  # Transformer深度
    "T_NUM_HEADS": 8               # 注意力头数
  },
  "AR_CONFIG": {
    "AUDIO_ENCODER": "wav2vec",    # wav2vec 或 mimi
    "T_DEPTH": 16,                 # AR Transformer深度
    "T_NUM_HEADS": 12,             # 注意力头数
    "PREV_RATIO": 2                # 历史上下文比例
  }
}
```

## 性能指标

- **推理速度**: ~25 FPS (RTX 3090, 无GAGAvatar)
- **推理速度**: ~5 FPS (RTX 3090, 含GAGAvatar)
- **模型大小**: ~200MB (ARTalk_wav2vec.pt)
- **输入**: 16kHz 单声道音频
- **输出**: 25 FPS, 512×512 RGB视频
- **延迟**: 实时 (音频长度 + 渲染时间)
